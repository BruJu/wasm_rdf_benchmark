#!/usr/bin/env python3

import datetime
import os
import random
import subprocess
import sys

os.chdir(os.path.dirname(sys.argv[0]))

KINDS = {
    "tree"      : { 'parse' : 1, 'query': 6 },
    "wasm_tree" : { 'parse' : 1, 'query': 6 },
    "graphy"    : { 'parse' : 1 },
    "n3"        : { 'parse' : 3 }
}

COMMAND = "./b_nodejs/loadMeasure.js {task} '{filename}' {kind}"

def main():
    # -- ArgParse
    if len(sys.argv) < 2:
        print("usage: {} <file> <number_of_runs = 1>".format(sys.argv[0]), file=sys.stderr)
        exit(0)
    
    filename = sys.argv[1]
    
    if len(sys.argv) >= 3:
        iterations = int(sys.argv[2])
    else:
        iterations = 1

    if len(sys.argv) >= 4:
        datasets = [kind for kind in filter(lambda x : x in KINDS, sys.argv[3:])]
    else:
        datasets = [kind for kind in KINDS]

    # -- Bench list

    list_of_tasks = []
    for _ in range(iterations):
        for dataset in datasets:
            for arg_mode in KINDS[dataset]:
                t = (dataset, arg_mode, KINDS[dataset][arg_mode])
                list_of_tasks.append(t)   

    random.shuffle(list_of_tasks)

    # -- Run the benchs

    csv = "csv/loadbench_{}.csv".format(
        str(datetime.datetime.now())[:19].replace(' ', '-').replace(':', '-'),
    )

    file_exists = os.path.isfile(csv)

    with open(csv, 'w+') as f:
        try:
            print("WRITING", csv, file=sys.stderr)
            if not file_exists:
                f.write("{}\n".format("dataset,nb_trees,file,nb_quads,memory_usage,loading_time"))
                f.flush()

            for dataset, arg, nb_trees in list_of_tasks:
                one_benchmark(f, filename, dataset, arg, nb_trees)

        except KeyboardInterrupt:
            sys.stdout.write("\r") # clear the '^C' that appears

def one_benchmark(f, filename, dataset, arg, nb_trees):
    cmd = COMMAND.format(task=arg, filename=filename, kind=dataset)
    res = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
    f.write("{},{},{},{}".format(dataset, nb_trees, filename, res.stdout.decode('utf8')))
    f.flush()
    print("DONE", dataset, nb_trees, filename, file=sys.stderr)

main()

'''
    if len(sys.argv) != 4:
        print(sys.argv)
        print("usage: {} <task> <tool> <kind>".format(sys.argv[0]), file=sys.stderr)
        print("  available tasks: {}".format(
            ",".join(QUERIES)
        ))
        print("  available tools: {}".format(
            ",".join(TOOLS)
        ))
        print("  available datasets: {}".format(
            ",".join(KINDS)
        ))
        exit(1)
        
    args = sys.argv[1:]
    task = args[0]
    tool = args[1]
    kind = args[2]


    nb_iter = int(os.getenv("N", "4"))

    benchmark(task, tool, kind, nb_iter)

def benchmark(task, tool, kind, nb_iter):
    if task not in QUERIES:
        print(task)
        print("available tasks: " + ", ".join(QUERIES), file=sys.stderr)
        exit(2)
    if tool not in TOOLS:
        print("------" + tool)
        print("available tools: " + ", ".join(TOOLS), file=sys.stderr)
        exit(3)
    if kind not in KINDS:
        print("Invalid kind: " + kind)
        print("available kinds: " + ", ".join(KINDS), file=sys.stderr)
        exit(8)


    csv = "csv/bench_{}.csv".format(
        str(datetime.datetime.now())[:19].replace(' ', '-').replace(':', '-'),
    )

    list_of_tasks = []

    for filename, size in FILES:
        for _ in range(nb_iter):
            t = (task, tool, kind, filename, size)
            list_of_tasks.append(t)
    
    run_benchmarks(list_of_tasks)


def mass_benchmark():
    NB_ITER = 2

    list_of_tasks = []
    for task in QUERIES:
        for kind in KINDS:
            for filename, size in FILES:
                for _ in range(NB_ITER):
                    if "rust" in KINDS[kind]:
                        t = (task, "rust", kind, filename, size)
                        list_of_tasks.append(t)
                    
                    if "rdfjsdataset" in KINDS[kind]:
                        t = (task, "rdfjsdataset", kind, filename, size)
                        list_of_tasks.append(t)

    run_benchmarks(list_of_tasks)


def exportation_dataset_impact(NB_ITER):
    list_of_tasks = []
    for task in QUERIES:
        for kind in ["fast", "fast_array", "wrap_fast"]:
            for filename, size in FILES:
                for _ in range(NB_ITER):
                    if "rust" in KINDS[kind]:
                        t = (task, "rust", kind, filename, size)
                        list_of_tasks.append(t)
                    
                    if "rdfjsdataset" in KINDS[kind]:
                        t = (task, "rdfjsdataset", kind, filename, size)
                        list_of_tasks.append(t)

    run_benchmarks(list_of_tasks)


def paperESWC(NB_ITER):
    list_of_tasks = []
    
    task = "query4" # S
    
    for filename, size in FILES:
        for _ in range(NB_ITER):
            t = (task, "rust", "tree", filename, size)
            list_of_tasks.append(t)

            for kind in ["tree", "wasm_tree", "graphy"]:
                if "rdfjsdataset" in KINDS[kind]:
                    t = (task, "rdfjsdataset", kind, filename, size)
                    list_of_tasks.append(t)

    task = "query" # POG

    for filename, size in FILES:
        for _ in range(NB_ITER):
            for kind in ["wasm_tree", "n3"]:
                if "rdfjsstore" in KINDS[kind]:
                    t = (task, "rdfjsstore", kind, filename, size)
                    list_of_tasks.append(t)

    run_benchmarks(list_of_tasks)

def measure_javascript(NB_ITER):
    list_of_tasks = []
    for task in QUERIES:
        for kind in ["fast", "fast_array", "tree", "wasm_tree", "array", "graphy"]:
            for filename, size in FILES:
                for _ in range(NB_ITER):
                    if "rdfjsdataset" in KINDS[kind]:
                        t = (task, "rdfjsdataset", kind, filename, size)
                        list_of_tasks.append(t)

    run_benchmarks(list_of_tasks)

def measure_tree(NB_ITER):
    list_of_tasks = []
    for task in ["query"]:
        for kind in ["tree", "tree_anti", "tree_array"]:
            for filename, size in FILES:
                for _ in range(NB_ITER):
                    if "rust" in KINDS[kind]:
                        t = (task, "rust", kind, filename, size)
                        list_of_tasks.append(t)

    run_benchmarks(list_of_tasks)


def run_benchmarks(list_of_tasks):
    random.shuffle(list_of_tasks)
    csv = "csv/bench_{}.csv".format(
        str(datetime.datetime.now())[:19].replace(' ', '-').replace(':', '-'),
    )

    file_exists = os.path.isfile(csv)

    with open(csv, 'w+') as f:
        try:
            print("WRITING", csv, file=sys.stderr)
            if not file_exists:
                f.write("tool,dataset,pattern,size,{}\n".format(HEADER))
                f.flush()

            for task, tool, kind, filename, size in list_of_tasks:
                one_benchmark(f, task, tool, kind, filename, size)

        except KeyboardInterrupt:
            sys.stdout.write("\r") # clear the '^C' that appears

def one_benchmark(f, task, tool, kind, filename, size):
    cmd = TOOLS[tool]
    cmd = cmd.format(task=task, filename=filename, kind=kind)
    res = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
    f.write("{},{},{},{},{}".format(tool, kind, QUERIES[task], size, res.stdout.decode('utf8')))
    f.flush()
    print("DONE", task, tool, kind, filename, file=sys.stderr)

#main()


#mass_benchmark()

#measure_javascript(20)
#measure_tree(20)
#exportation_dataset_impact(20)

def oooh():
    NB_ITER = 20
    list_of_tasks = []

    for size in range(5000, 100000, 5000):
        for _ in range(NB_ITER):
            t = ("query", "rdfjsdataset", "wasm_tree", 'data/cpersondata_en_' + str(size) + ".ttl", size)
            list_of_tasks.append(t)


    for task in QUERIES:
        for kind in ["tree", "wasm_tree", "array", "graphy"]:
            for filename, size in FILES:
                for _ in range(NB_ITER):
                    if "rdfjsdataset" in KINDS[kind]:
                        t = (task, "rdfjsdataset", kind, filename, size)
                        list_of_tasks.append(t)
    
    for task in QUERIES:
        for kind in ["tree"]:
            for filename, size in FILES:
                for _ in range(NB_ITER):
                    if "rust" in KINDS[kind]:
                        t = (task, "rust", kind, filename, size)
                        list_of_tasks.append(t)
    

    for task in QUERIES:
        for kind in ["fast", "fast_array", "wrap_fast"]:
            for filename, size in FILES:
                for _ in range(NB_ITER):
                    if "rust" in KINDS[kind]:
                        t = (task, "rust", kind, filename, size)
                        list_of_tasks.append(t)
                    
                    if "rdfjsdataset" in KINDS[kind]:
                        t = (task, "rdfjsdataset", kind, filename, size)
                        list_of_tasks.append(t)
    
    run_benchmarks(list_of_tasks)


def ooop():
    NB_ITER = 40
    list_of_tasks = []

    for task in QUERIES:
        for kind in ["wrap_tree", "tree", "wasm_tree", "graphy"]:
            for filename, size in FILES:
                if size != 1000000:
                    continue

                for _ in range(NB_ITER):
                    if "rdfjsdataset" in KINDS[kind]:
                        t = (task, "rdfjsdataset", kind, filename, size)
                        list_of_tasks.append(t)
    
    
    run_benchmarks(list_of_tasks)

paperESWC(20)
'''